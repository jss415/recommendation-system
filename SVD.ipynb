{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6e40fa3-aecd-40b8-b77b-87e080825ad6",
   "metadata": {},
   "source": [
    "# Singular Value Decomposition (SVD) Based Recommendation System Using Surprise Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c299e48d-07cf-41b6-8b84-e0c7e19b7aeb",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97c2c25d-30d6-4b7b-8214-cf1b40e85852",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support as prfs\n",
    "from sklearn.metrics import ndcg_score as NDCG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ef128f-1e94-4896-9253-33d19c9476f1",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d816b442-4546-4fd7-966c-cb82eba4d00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "reader = Reader(line_format='user item rating timestamp', sep='::')\n",
    "data = Dataset.load_from_file('ratings.dat', reader=reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5627757b-fe3d-4acb-bcdc-7dcd0bf16e92",
   "metadata": {},
   "source": [
    "## Data preprocessing: Spltting the dataset into 80% training and 20% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d07df9e6-cce0-4bfd-86cb-b40ee8736b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4786428-2e99-40bd-ab3b-326018628a11",
   "metadata": {},
   "source": [
    "## Using GridSearchCV to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33b25b1c-f7a7-4b84-a0b6-64d784deab03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST RMSE: \t 0.8734795898130537\n",
      "BEST params: \t {'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.02}\n"
     ]
    }
   ],
   "source": [
    "params = { \"n_epochs\":range(10,100,10), \"lr_all\":[0.002, 0.005], \"reg_all\":[0.02, 0.4, 0.6] }\n",
    "grid_search = GridSearchCV(SVD, params, measures=[\"rmse\", \"mae\"], refit=True, cv=5)\n",
    "grid_search.fit(data)\n",
    "\n",
    "training_parameters = grid_search.best_params[\"rmse\"]\n",
    "print(\"BEST RMSE: \\t\", grid_search.best_score[\"rmse\"])\n",
    "print(\"BEST params: \\t\", grid_search.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6728bfaa-bdfc-4bd2-9626-d00e4bd72afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAE score: 0.6858446360633019\n",
      "Best MAE parameters: {'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.02}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best MAE score:\", grid_search.best_score['mae'])\n",
    "print(\"Best MAE parameters:\", grid_search.best_params['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc0c196-98cc-4b93-a302-9fb548571ec1",
   "metadata": {},
   "source": [
    "## Train the model using the best parameters and test the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8ca8fb9-afd1-4bb5-82f4-c5a536000c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7f412d303430>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd=SVD(n_epochs=training_parameters['n_epochs'], lr_all=training_parameters['lr_all'], reg_all=training_parameters['reg_all'])\n",
    "svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7b6e56-dd37-4425-9c21-391a597ce04b",
   "metadata": {},
   "source": [
    "## Calculate precision, recall, ndcg, and f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "725f5ae8-6c4d-48bf-9d63-286338f3165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_calculation(predictions, threshold=3.5):\n",
    "    # First map the predictions to each user.\n",
    "    user_predict_true = defaultdict(list)\n",
    "    for user_id, movie_id, true_rating, predicted_rating, _ in predictions:\n",
    "        user_predict_true[user_id].append((predicted_rating, true_rating))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for user_id, user_ratings in user_predict_true.items():\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        # Number of relevant items\n",
    "        no_of_relevant_items = sum((true_rating >= threshold) for (predicted_rating, true_rating) in user_ratings)\n",
    "        # Number of recommended items in top 10\n",
    "        no_of_recommended_items = sum((predicted_rating >= threshold) for (predicted_rating, true_rating) in user_ratings[:10])\n",
    "        # Number of relevant and recommended items in top 10\n",
    "        no_of_relevant_and_recommended_items = sum(((true_rating >= threshold) and (predicted_rating >= threshold)) for (predicted_rating, true_rating) in user_ratings[:10])\n",
    "        # Precision: Proportion of recommended items that are relevant\n",
    "        precisions[user_id] = no_of_relevant_and_recommended_items / no_of_recommended_items if no_of_recommended_items != 0 else 1\n",
    "        # Recall: Proportion of relevant items that are recommended\n",
    "        recalls[user_id] = no_of_relevant_and_recommended_items / no_of_relevant_items if no_of_relevant_items != 0 else 1\n",
    "\n",
    "    # Averaging the values for all users\n",
    "    average_precision=sum(precision for precision in precisions.values()) / len(precisions)\n",
    "    average_recall=sum(recall for recall in recalls.values()) / len(recalls)\n",
    "    F_score=(2*average_precision*average_recall) / (average_precision + average_recall)\n",
    "    \n",
    "    return [average_precision, average_recall, F_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9aaf30a-d67d-4042-82b5-6a79e3ef1f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_predicted = svd.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bbce70e-8fb9-4883-8007-5cd7041a8954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ade514d-8638-46c9-8b2d-198298d252c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: \t0.8041355218257376\n",
      "Recall: \t0.552559265793466\n",
      "F_score: \t0.6550220986965127\n"
     ]
    }
   ],
   "source": [
    "precision, recall, F_score = precision_recall_calculation(test_set_predicted, threshold=3.5)\n",
    "print(\"Precision: \\t{}\".format(precision))\n",
    "print(\"Recall: \\t{}\".format(recall))\n",
    "print(\"F_score: \\t{}\".format(F_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dc8c87f-cabe-4ffe-ae9e-2dcee1d61bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score: 0.8520059180089629\n",
      "Best RMSE parameters: {'n_factors': 150, 'n_epochs': 40, 'lr_all': 0.01, 'reg_all': 0.06}\n",
      "Best MAE score: 0.6717937085490093\n",
      "Best MAE parameters: {'n_factors': 100, 'n_epochs': 40, 'lr_all': 0.01, 'reg_all': 0.06}\n"
     ]
    }
   ],
   "source": [
    "# Print the best RMSE and MAE scores and the corresponding hyperparameters\n",
    "print(\"Best RMSE score:\", grid_search.best_score['rmse'])\n",
    "print(\"Best RMSE parameters:\", grid_search.best_params['rmse'])\n",
    "print(\"Best MAE score:\", grid_search.best_score['mae'])\n",
    "print(\"Best MAE parameters:\", grid_search.best_params['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ae7dd29-51e1-422a-9fbb-da2d102939c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7f412d3a0730>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the algorithm with the best hyperparameters\n",
    "best_algo = SVD(n_factors=grid_search.best_params['rmse']['n_factors'], n_epochs=grid_search.best_params['rmse']['n_epochs'], lr_all=grid_search.best_params['rmse']['lr_all'], reg_all=grid_search.best_params['rmse']['reg_all'])\n",
    "best_algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "344ab76d-8a54-4587-8f51-02ab0a9f8614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for the test set\n",
    "predictions = best_algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a84298d-f80a-4e98-9606-8c4984e52a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8524\n",
      "RMSE: 0.8524218234875797\n",
      "MAE:  0.6718\n",
      "MAE: 0.6717813589487042\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute and print the RMSE and MAE scores for the test set\n",
    "print(\"RMSE:\", accuracy.rmse(predictions))\n",
    "print(\"MAE:\", accuracy.mae(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8849088f-e9ed-47d4-8a00-71b4d61fc675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5172525182169726\n",
      "Recall: 0.4512302416492537\n",
      "F1 score: 0.41964862661842606\n",
      "NDCG: 0.9929508043419567\n"
     ]
    }
   ],
   "source": [
    "# Create empty lists for true and predicted ratings\n",
    "true_ratings = []\n",
    "pred_ratings = []\n",
    "\n",
    "# Fill in the lists with true and predicted ratings\n",
    "for prediction in predictions:\n",
    "    true_ratings.append(prediction.r_ui)\n",
    "    pred_ratings.append(prediction.est)\n",
    "\n",
    "# Calculate precision, recall, F1 score using scikit-learn\n",
    "precision, recall, fscore, _ = prfs(true_ratings, [int(round(rating)) for rating in pred_ratings], average='weighted')\n",
    "\n",
    "# Calculate NDCG using scikit-learn\n",
    "ndcg = NDCG([true_ratings], [pred_ratings])\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 score:\", fscore)\n",
    "print(\"NDCG:\", ndcg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
